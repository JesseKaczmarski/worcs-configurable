
@book{10.5555/1593511,
  title = {Python 3 Reference Manual},
  author = {Van Rossum, Guido and Drake, Fred L.},
  date = {2009},
  publisher = {{CreateSpace}},
  location = {{Scotts Valley, CA}},
  isbn = {1-4414-1269-7}
}

@article{aalbersbergMakingScienceTransparent2018,
  title = {Making {{Science Transparent By Default}}; {{Introducing}} the {{TOP Statement}}},
  author = {Aalbersberg, IJsbrand Jan and Appleyard, Tom and Brookhart, Sarah and Carpenter, Todd and Clarke, Michael and Curry, Stephen and Dahl, Josh and DeHaven, Alexander Carl and Eich, Eric and Franko, Maryrose and Freedman, Len and Graf, Chris and Grant, Sean and Hanson, Brooks and Joseph, Heather and Kiermer, Veronique and Kramer, Bianca and Kraut, Alan and Karn, Roshan Kumar and Lee, Carole and MacFarlane, Aki and Martone, Maryann and Mayo-Wilson, Evan and McNutt, Marcia and McPhail, Meredith and Mellor, David Thomas and Moher, David and Mudditt, Alison and Nosek, Brian A. and Orland, Belinda and Parker, Timothy H. and Parsons, Mark and Patterson, Mark and Santos, Solange and Shore, Carolyn and Simons, Daniel J. and Spellman, Bobbie and Spies, Jeffrey Robert and Spitzer, Matthew and Stodden, Victoria and Swaminathan, Sowmya and Sweet, Deborah and Tsui, Anne and Vazire, Simine},
  date = {2018-02-15},
  doi = {10.31219/osf.io/sm78t},
  url = {https://osf.io/sm78t},
  urldate = {2020-01-08},
  abstract = {In order to increase the replicability of scientific work, the scientific community has called for practices designed to increase the transparency of research (McNutt, 2014; Nosek et al., 2015). The validity of a scientific claim depends not on the reputation of those making the claim, the venue in which the claim is made, or the novelty of the result, but rather on the empirical evidence provided by the underlying data and methods. Proper evaluation of  the merits of scientific findings requires availability of the methods, materials, and data and the reasoned argument that serve as the basis for the published conclusions (Claerbout and Karrenbach 1992; Donoho et al 2009; Stodden et al 2013; Borwein et al 2013; Munafò et al, 2017). Wide and growing support for these principles (see, for example, signatories to Declaration on Research Assessment, DORA, https://sfdora.org/, and the Transparency and Openness Promotion Guidelines https://cos.io/our-services/top-guidelines/) must be coupled with guidelines to increase open sharing of data and research materials, use of reporting guidelines, preregistration, and replication. We propose that, going forward, authors of all scientific articles disclose the availability and location of all research items, including data, materials, and code, related to their published articles in what we will refer to as a TOP Statement.}
}

@article{aczelConsensusbasedTransparencyChecklist2019,
  title = {A Consensus-Based Transparency Checklist},
  author = {Aczel, Balazs and Szaszi, Barnabas and Sarafoglou, Alexandra and Kekecs, Zoltan and Kucharský, Šimon and Benjamin, Daniel and Chambers, Christopher D. and Fisher, Agneta and Gelman, Andrew and Gernsbacher, Morton A. and Ioannidis, John P. and Johnson, Eric and Jonas, Kai and Kousta, Stavroula and Lilienfeld, Scott O. and Lindsay, D. Stephen and Morey, Candice C. and Munafò, Marcus and Newell, Benjamin R. and Pashler, Harold and Shanks, David R. and Simons, Daniel J. and Wicherts, Jelte M. and Albarracin, Dolores and Anderson, Nicole D. and Antonakis, John and Arkes, Hal R. and Back, Mitja D. and Banks, George C. and Beevers, Christopher and Bennett, Andrew A. and Bleidorn, Wiebke and Boyer, Ty W. and Cacciari, Cristina and Carter, Alice S. and Cesario, Joseph and Clifton, Charles and Conroy, Ronán M. and Cortese, Mike and Cosci, Fiammetta and Cowan, Nelson and Crawford, Jarret and Crone, Eveline A. and Curtin, John and Engle, Randall and Farrell, Simon and Fearon, Pasco and Fichman, Mark and Frankenhuis, Willem and Freund, Alexandra M. and Gaskell, M. Gareth and Giner-Sorolla, Roger and Green, Don P. and Greene, Robert L. and Harlow, Lisa L. and de la Guardia, Fernando Hoces and Isaacowitz, Derek and Kolodner, Janet and Lieberman, Debra and Logan, Gordon D. and Mendes, Wendy B. and Moersdorf, Lea and Nyhan, Brendan and Pollack, Jeffrey and Sullivan, Christopher and Vazire, Simine and Wagenmakers, Eric-Jan},
  date = {2019-12-02},
  journaltitle = {Nature Human Behaviour},
  shortjournal = {Nat Hum Behav},
  pages = {1--3},
  issn = {2397-3374},
  doi = {10.1038/s41562-019-0772-6},
  url = {https://www.nature.com/articles/s41562-019-0772-6},
  urldate = {2020-01-08},
  abstract = {We present a consensus-based checklist to improve and document the transparency of research reports in social and behavioural research. An accompanying online application allows users to complete the form and generate a report that they can submit with their manuscript or post to a public repository.},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\5T92PG4Y\\Aczel et al_2019_A consensus-based transparency checklist.pdf;C\:\\Users\\lissa102\\Zotero\\storage\\ZLCD57B9\\s41562-019-0772-6.html},
  langid = {english}
}

@article{adolphOpenBehavioralScience2012,
  title = {Toward {{Open Behavioral Science}}},
  author = {Adolph, Karen E. and Gilmore, Rick O. and Freeman, Clinton and Sanderson, Penelope and Millman, David},
  date = {2012-07},
  journaltitle = {Psychological Inquiry},
  shortjournal = {Psychological Inquiry},
  volume = {23},
  pages = {244--247},
  issn = {1047-840X, 1532-7965},
  doi = {10.1080/1047840X.2012.705133},
  url = {http://www.tandfonline.com/doi/abs/10.1080/1047840X.2012.705133},
  urldate = {2019-08-30},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\PYPE6J4K\\Adolph et al. - 2012 - Toward Open Behavioral Science.pdf},
  keywords = {open developmental science},
  langid = {english},
  number = {3}
}

@online{allaireMarkdownPythonEngine2020,
  title = {R {{Markdown Python Engine}}},
  author = {Allaire, J. J. and Ushey, Kevin and RStudio and Tang, Yuan},
  date = {2020},
  url = {https://rstudio.github.io/reticulate/articles/r_markdown.html},
  urldate = {2020-01-13},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\WSHC7J3P\\r_markdown.html}
}

@book{allaireRticlesArticleFormats2020,
  title = {Rticles: {{Article}} Formats for r Markdown},
  author = {Allaire, JJ and Xie, Yihui and {R Foundation} and Wickham, Hadley and {Journal of Statistical Software} and Vaidyanathan, Ramnath and {Association for Computing Machinery} and Boettiger, Carl and {Elsevier} and Broman, Karl and Mueller, Kirill and Quast, Bastiaan and Pruim, Randall and Marwick, Ben and Wickham, Charlotte and Keyes, Oliver and Yu, Miao and Emaasit, Daniel and Onkelinx, Thierry and Gasparini, Alessandro and Desautels, Marc-Andre and Leutnant, Dominik and {MDPI} and {Taylor and Francis} and Ögreden, Oguzhan and Hance, Dalton and Nüst, Daniel and Uvesten, Petter and Campitelli, Elio and Muschelli, John and Kamvar, Zhian N. and Ross, Noam and Cannoodt, Robrecht and Luguern, Duncan and Kaplan, David M.},
  date = {2020},
  url = {https://CRAN.R-project.org/package=rticles}
}

@software{austPapajaPrepareReproducible2020,
  title = {Papaja: {{Prepare}} Reproducible {{APA}} Journal Articles with {{R Markdown}}.},
  author = {Aust, Frederik and Barth, Marius},
  date = {2020-01-28T22:33:21Z},
  origdate = {2014-07-20T11:43:41Z},
  url = {https://github.com/crsh/papaja},
  urldate = {2020-02-04},
  abstract = {papaja (Preparing APA Journal Articles) is an R package that provides document formats to produce complete APA manscripts from RMarkdown-files (PDF and Word documents) and helper functions that fac...},
  keywords = {apa,apa-guidelines,journal,manuscript,psychology,r,reproducible-paper,reproducible-research,rmarkdown},
  version = {0.1.0.9842}
}

@software{austPreregMarkdownTemplates2019,
  title = {Prereg: {{R Markdown Templates}} to {{Preregister Scientific Studies}}},
  shorttitle = {Prereg},
  author = {Aust, Frederik},
  date = {2019-01-09},
  url = {https://CRAN.R-project.org/package=prereg},
  urldate = {2020-01-30},
  abstract = {Provides a collection of templates to author preregistration documents for scientific studies in PDF format.},
  version = {0.4.0}
}

@article{bauerExpandingReachPsychological2019,
  title = {Expanding the {{Reach}} of {{Psychological Science}}},
  author = {Bauer, Patricia J.},
  date = {2019-12-18},
  journaltitle = {Psychological Science},
  shortjournal = {Psychol Sci},
  pages = {0956797619898664},
  issn = {0956-7976},
  doi = {10.1177/0956797619898664},
  url = {https://doi.org/10.1177/0956797619898664},
  urldate = {2020-01-08},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\RIZC4MV4\\2019_Expanding the Reach of Psychological Science.pdf},
  langid = {english}
}

@article{blischakQuickIntroductionVersion2016,
  title = {A {{Quick Introduction}} to {{Version Control}} with {{Git}} and {{GitHub}}},
  author = {Blischak, John D. and Davenport, Emily R. and Wilson, Greg},
  date = {2016-01-19},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {12},
  pages = {e1004668},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1004668},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004668},
  urldate = {2019-10-26},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\NYSUERQ3\\Blischak et al_2016_A Quick Introduction to Version Control with Git and GitHub.pdf;C\:\\Users\\lissa102\\Zotero\\storage\\BCILHZ8S\\article.html},
  keywords = {Cloning,Control systems,Graphical user interface,Kidneys,Machine learning,Morphology (linguistics),Scientists,Software development},
  langid = {english},
  number = {1}
}

@unpublished{brinkmanWidescaleAdoptionOpen2020,
  title = {Towards {{Wide}}-Scale {{Adoption}} of {{Open}}  {{Science Practices}}: {{The Role}} of {{Bottom}}-up  {{Open Science Communities}}},
  author = {Brinkman, Loek and Armeni, Kristijan and Schettino, Antonio and Eerland, Anita and Heininga, Vera E and Fijten, Rianne and Sjoerds, Zsuzsika and Masselink, Maurits},
  date = {2020},
  abstract = {Open science (OS) increases the quality, efficiency, and impact of science. This has been recognised by scholars, funders, and policymakers worldwide. However, despite the increasing availability of infrastructure supporting OS and the rise in policies and incentives to change behavior, OS practices are often not the norm. While pioneering researchers are developing and embracing OS practices, the majority sticks to the status quo. To transition from pioneering to common practice, we need to engage a critical proportion of the academic community. In this transition, open science communities (OSCs) play a key role. OSCs are bottom-up learning groups of scholars that discuss OS practices, within and across disciplines. They make OS knowledge and know-how more visible and accessible, and facilitate communication amongst scholars and policy makers. By the same token, these scholars also engage in shaping the transition to OS such that it is most beneficial for researchers, science, and society. Over the past two years, ten OSCs were founded in several Dutch university cities, with over 400 members in total. In other countries, scholars are starting similar OSCs. In this paper, we discuss the pivotal role OSCs can play in the large-scale transition to OS and provide practical information to start your own local OSC. We stress that, despite the grassroots character of OSCs, support from universities is critical for OSCs to be viable, effective, and sustainable.},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\6SPVL5S6\\Brinkman et al. - Open Science Communities Netherlands (OSC-NL).pdf},
  langid = {english}
}

@online{brownHowLearnedStop2017,
  title = {How {{I}} Learned to Stop Worrying and Love the Coming Archivability Crisis in Scientific Software},
  author = {Brown, C. Titus},
  date = {2017},
  url = {http://ivory.idyll.org/blog/2017-pof-software-archivability.html},
  urldate = {2020-01-13},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\LRI2PYYL\\2017-pof-software-archivability.html}
}

@data{campbellAmericanNationalElection1984,
  title = {American {{National Election Study}}, 1948: {{Version}} 3},
  shorttitle = {American {{National Election Study}}, 1948},
  author = {Campbell, Angus and Kahn, Robert L.},
  date = {1984-05-08},
  publisher = {{Inter-university Consortium for Political and Social Research}},
  doi = {10.3886/ICPSR07218.v3},
  url = {http://www.icpsr.umich.edu/ICPSR/studies/07218/version/3},
  urldate = {2020-11-01},
  abstract = {Citation of articles is routine and well­formulated. Similar standards can be applied to citation of data, code, and materials to recognize and credit these as original intellectual contributions. Level 1 recommends citation standards, Level 2 requires adherence to citation standards, and Level 3 requires and enforces adherence to citation standards.},
  langid = {english}
}

@article{coyneReplicationInitiativesWill2016,
  title = {Replication Initiatives Will Not Salvage the Trustworthiness of Psychology},
  author = {Coyne, James C.},
  date = {2016-05-31},
  journaltitle = {BMC Psychology},
  shortjournal = {BMC Psychology},
  volume = {4},
  pages = {28},
  issn = {2050-7283},
  doi = {10.1186/s40359-016-0134-3},
  url = {https://doi.org/10.1186/s40359-016-0134-3},
  urldate = {2019-08-31},
  abstract = {Replication initiatives in psychology continue to gather considerable attention from far outside the field, as well as controversy from within. Some accomplishments of these initiatives are noted, but this article focuses on why they do not provide a general solution for what ails psychology. There are inherent limitations to mass replications ever being conducted in many areas of psychology, both in terms of their practicality and their prospects for improving the science. Unnecessary compromises were built into the ground rules for design and publication of the Open Science Collaboration: Psychology that undermine its effectiveness. Some ground rules could actually be flipped into guidance for how not to conduct replications. Greater adherence to best publication practices, transparency in the design and publishing of research, strengthening of independent post-publication peer review and firmer enforcement of rules about data sharing and declarations of conflict of interest would make many replications unnecessary. Yet, it has been difficult to move beyond simple endorsement of these measures to consistent implementation. Given the strong institutional support for questionable publication practices, progress will depend on effective individual and collective use of social media to expose lapses and demand reform. Some recent incidents highlight the necessity of this.},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\FBLTNNET\\Coyne - 2016 - Replication initiatives will not salvage the trust.pdf},
  keywords = {open developmental science,replication},
  number = {1}
}

@online{dariah-campusOpenScienceJust2019,
  title = {Open {{Science}} Is {{Just Good Science}}},
  author = {DARIAH-Campus},
  date = {2019-08-16T00:00:00.000Z},
  journaltitle = {DARIAH Campus},
  url = {https://campus.dariah.eu/resource/open-science-is-just-good-science},
  urldate = {2020-05-23},
  abstract = {DARIAH-CAMPUS is a discovery framework and hosting platform for DARIAH learning resources. Currently in beta.},
  langid = {english}
}

@online{EditorsPsychOpen,
  title = {For {{Editors}}: {{PsychOpen}}},
  url = {https://www.psychopen.eu/for-editors/},
  urldate = {2020-01-08}
}

@online{fosterconsortiumOpenScienceDefinition,
  title = {Open {{Science Definition}}},
  author = {FOSTER consortium},
  url = {https://www.fosteropenscience.eu/foster-taxonomy/open-science-definition},
  urldate = {2020-11-01},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\FRAD8D5B\\open-science-definition.html}
}

@article{gauMoreBrainDroppings,
  title = {More Brain Droppings on the Replication Crisis},
  author = {Gau, Remi},
  pages = {52},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\IEXXQU7X\\Gau - More brain droppings on the replication crisis.pdf},
  langid = {english}
}

@article{gelmanStatisticalCrisisScience2014,
  title = {The Statistical Crisis in Science: Data-Dependent Analysis--a \&quot;Garden of Forking Paths\&quot;--Explains Why Many Statistically Significant Comparisons Don't Hold Up},
  shorttitle = {The Statistical Crisis in Science},
  author = {Gelman, Andrew and Loken, Eric},
  date = {2014-11-01},
  journaltitle = {American Scientist},
  volume = {102},
  pages = {460--466},
  issn = {00030996},
  url = {https://go.gale.com/ps/i.do?p=AONE&sw=w&issn=00030996&v=2.1&it=r&id=GALE%7CA389260653&sid=googleScholar&linkaccess=abs},
  urldate = {2020-02-08},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\M37N35RL\\anonymous.html},
  langid = {english},
  number = {6}
}

@book{goldfeldSimstudySimulationStudy2020,
  title = {Simstudy: {{Simulation}} of Study Data},
  author = {Goldfeld, Keith},
  date = {2020},
  url = {https://CRAN.R-project.org/package=simstudy}
}

@book{grolemundDataScience2017,
  title = {R for {{Data Science}}},
  author = {Grolemund, Garrett and Wickham, Hadley},
  date = {2017},
  publisher = {{O'Reilly}},
  url = {https://r4ds.had.co.nz/},
  urldate = {2020-05-19},
  abstract = {This book will teach you how to do data science with R: You’ll learn how to get your data into R, get it into the most useful structure, transform it, visualise it and model it. In this book, you will find a practicum of skills for data science. Just as a chemist learns how to clean test tubes and stock a lab, you’ll learn how to clean data and draw plots—and many other things besides. These are the skills that allow data science to happen, and here you will find the best practices for doing each of these things with R. You’ll learn how to use the grammar of graphics, literate programming, and reproducible research to save time. You’ll also learn how to manage cognitive resources to facilitate discoveries when wrangling, visualising, and exploring data.},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\8LSGEMNP\\r4ds.had.co.nz.html}
}

@report{GuidelinesTransparencyOpenness,
  title = {Guidelines~for~{{Transparency}}~and~{{Openness~Promotion}}~({{TOP}})~in~{{Journal~Policies}}~and~ {{Practices}}: “{{The~TOP~Guidelines}}”},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\W2YYCR8I\\TOPGuidelines.pdf}
}

@software{hallquistMplusAutomationPackageFacilitating2018,
  title = {{{MplusAutomation}}: {{An R Package}} for {{Facilitating Large}}-{{Scale Latent Variable Analyses}} in {{Mplus}}},
  shorttitle = {{{MplusAutomation}}},
  author = {Hallquist, Michael and Wiley, Joshua and Van Lissa, Caspar J.},
  date = {2018-11-25},
  url = {https://CRAN.R-project.org/package=MplusAutomation},
  urldate = {2020-02-05},
  abstract = {Leverages the R language to automate latent variable model estimation and interpretation using 'Mplus', a powerful latent variable modeling program developed by Muthen and Muthen ({$<$}http://www.statmodel.com{$>$}). Specifically, this package provides routines for creating related groups of models, running batches of models, and extracting and tabulating model parameters and fit statistics.},
  keywords = {Psychometrics},
  version = {0.7-3}
}

@article{helgessonResponsibilityScientificMisconduct2018,
  title = {Responsibility for Scientific Misconduct in Collaborative Papers},
  author = {Helgesson, Gert and Eriksson, Stefan},
  date = {2018-09-01},
  journaltitle = {Medicine, Health Care and Philosophy},
  shortjournal = {Med Health Care and Philos},
  volume = {21},
  pages = {423--430},
  issn = {1572-8633},
  doi = {10.1007/s11019-017-9817-7},
  url = {https://doi.org/10.1007/s11019-017-9817-7},
  urldate = {2019-10-25},
  abstract = {This paper concerns the responsibility of co-authors in cases of scientific misconduct. Arguments in research integrity guidelines and in the bioethics literature concerning authorship responsibilities are discussed. It is argued that it is unreasonable to claim that for every case where a research paper is found to be fraudulent, each author is morally responsible for all aspects of that paper, or that one particular author has such a responsibility. It is further argued that it is more constructive to specify what task responsibilities come with different roles in a project and describe what kinds of situations or events call for some kind of action, and what the appropriate actions might be.},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\SK7V3ZIB\\Helgesson_Eriksson_2018_Responsibility for scientific misconduct in collaborative papers.pdf},
  keywords = {Accountability,Authorship,Research ethics,Research integrity,Responsibility,Scientific misconduct},
  langid = {english},
  number = {3}
}

@article{johnMeasuringPrevalenceQuestionable2012,
  title = {Measuring the {{Prevalence}} of {{Questionable Research Practices With Incentives}} for {{Truth Telling}}},
  author = {John, Leslie K. and Loewenstein, George and Prelec, Drazen},
  date = {2012-05-01},
  journaltitle = {Psychological Science},
  shortjournal = {Psychol Sci},
  volume = {23},
  pages = {524--532},
  issn = {0956-7976},
  doi = {10.1177/0956797611430953},
  url = {https://doi.org/10.1177/0956797611430953},
  urldate = {2020-02-08},
  abstract = {Cases of clear scientific misconduct have received significant media attention recently, but less flagrantly questionable research practices may be more prevalent and, ultimately, more damaging to the academic enterprise. Using an anonymous elicitation format supplemented by incentives for honest reporting, we surveyed over 2,000 psychologists about their involvement in questionable research practices. The impact of truth-telling incentives on self-admissions of questionable research practices was positive, and this impact was greater for practices that respondents judged to be less defensible. Combining three different estimation methods, we found that the percentage of respondents who have engaged in questionable practices was surprisingly high. This finding suggests that some questionable practices may constitute the prevailing research norm.},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\TJKTAI5M\\John et al_2012_Measuring the Prevalence of Questionable Research Practices With Incentives for.pdf},
  keywords = {disclosure,judgment,methodology,professional standards},
  langid = {english},
  number = {5}
}

@article{kerrHARKingHypothesizingResults1998,
  title = {{{HARKing}}: Hypothesizing after the Results Are Known},
  shorttitle = {{{HARKing}}},
  author = {Kerr, N. L.},
  date = {1998},
  journaltitle = {Personality and Social Psychology Review: An Official Journal of the Society for Personality and Social Psychology, Inc},
  shortjournal = {Pers Soc Psychol Rev},
  volume = {2},
  pages = {196--217},
  issn = {1088-8683},
  doi = {10.1207/s15327957pspr0203_4},
  abstract = {This article considers a practice in scientific communication termed HARKing (Hypothesizing After the Results are Known). HARKing is defined as presenting a post hoc hypothesis (i.e., one based on or informed by one's results) in one's research report as i f it were, in fact, an a priori hypotheses. Several forms of HARKing are identified and survey data are presented that suggests that at least some forms of HARKing are widely practiced and widely seen as inappropriate. I identify several reasons why scientists might HARK. Then I discuss several reasons why scientists ought not to HARK. It is conceded that the question of whether HARKing ' s costs exceed its benefits is a complex one that ought to be addressed through research, open discussion, and debate. To help stimulate such discussion (and for those such as myself who suspect that HARKing's costs do exceed its benefits), I conclude the article with some suggestions for deterring HARKing.},
  eprint = {15647155},
  eprinttype = {pmid},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\N57L34VT\\Kerr - 1998 - HARKing hypothesizing after the results are known.pdf},
  langid = {english},
  number = {3}
}

@article{kidwellBadgesAcknowledgeOpen2016,
  title = {Badges to {{Acknowledge Open Practices}}: {{A Simple}}, {{Low}}-{{Cost}}, {{Effective Method}} for {{Increasing Transparency}}},
  shorttitle = {Badges to {{Acknowledge Open Practices}}},
  author = {Kidwell, Mallory C. and Lazarević, Ljiljana B. and Baranski, Erica and Hardwicke, Tom E. and Piechowski, Sarah and Falkenberg, Lina-Sophia and Kennett, Curtis and Slowik, Agnieszka and Sonnleitner, Carina and Hess-Holden, Chelsey and Errington, Timothy M. and Fiedler, Susann and Nosek, Brian A.},
  date = {2016-05-12},
  journaltitle = {PLOS Biology},
  shortjournal = {PLOS Biology},
  volume = {14},
  pages = {e1002456},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.1002456},
  url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002456},
  urldate = {2019-08-31},
  abstract = {Beginning January 2014, Psychological Science gave authors the opportunity to signal open data and materials if they qualified for badges that accompanied published articles. Before badges, less than 3\% of Psychological Science articles reported open data. After badges, 23\% reported open data, with an accelerating trend; 39\% reported open data in the first half of 2015, an increase of more than an order of magnitude from baseline. There was no change over time in the low rates of data sharing among comparison journals. Moreover, reporting openness does not guarantee openness. When badges were earned, reportedly available data were more likely to be actually available, correct, usable, and complete than when badges were not earned. Open materials also increased to a weaker degree, and there was more variability among comparison journals. Badges are simple, effective signals to promote open practices and improve preservation of data and materials by using independent repositories.},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\35AQ9U5U\\Kidwell et al. - 2016 - Badges to Acknowledge Open Practices A Simple, Lo.pdf;C\:\\Users\\lissa102\\Zotero\\storage\\NGFUB647\\article.html},
  keywords = {Behavior,Cognitive psychology,Experimental psychology,Open data,open developmental science,Open science,Psychology,Research assessment,Scientific publishing},
  langid = {english},
  number = {5}
}

@article{klebelPeerReviewPreprint2020,
  title = {Peer Review and Preprint Policies Are Unclear at Most Major Journals},
  author = {Klebel, Thomas and Reichmann, Stefan and Polka, Jessica and McDowell, Gary and Penfold, Naomi and Hindle, Samantha and Ross-Hellauer, Tony},
  date = {2020-01-30},
  journaltitle = {bioRxiv},
  pages = {2020.01.24.918995},
  doi = {10.1101/2020.01.24.918995},
  url = {https://www.biorxiv.org/content/10.1101/2020.01.24.918995v1},
  urldate = {2020-02-05},
  abstract = {{$<$}p{$>$}Clear and findable publishing policies are important for authors to choose appropriate journals for publication. We investigated the clarity of policies of 171 major academic journals across disciplines regarding peer review and preprinting. 31.6\% of journals surveyed do not provide information on the type of peer review they use. Information on whether preprints can be posted or not is unclear in 39.2\% of journals. 58.5\% of journals offer no clear information on whether reviewer identities are revealed to authors. Around 75\% of journals have no clear policy on coreviewing, citation of preprints, and publication of reviewer identities. Information regarding practices of Open Peer Review is even more scarce, with \&lt;20\% of journals providing clear information. Having found a lack of clear information, we conclude by examining the implications this has for researchers (especially early career) and the spread of open research practices.{$<$}/p{$>$}},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\CZ5JNZPP\\Klebel et al_2020_Peer review and preprint policies are unclear at most major journals.pdf;C\:\\Users\\lissa102\\Zotero\\storage\\LCSN629R\\2020.01.24.html},
  langid = {english}
}

@article{kulkeImplicitTheoryMind2018,
  title = {Is {{Implicit Theory}} of {{Mind}} a {{Real}} and {{Robust Phenomenon}}? {{Results From}} a {{Systematic Replication Study}}},
  shorttitle = {Is {{Implicit Theory}} of {{Mind}} a {{Real}} and {{Robust Phenomenon}}?},
  author = {Kulke, Louisa and von Duhn, Britta and Schneider, Dana and Rakoczy, Hannes},
  date = {2018-06},
  journaltitle = {Psychological Science},
  shortjournal = {Psychol Sci},
  volume = {29},
  pages = {888--900},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/0956797617747090},
  url = {http://journals.sagepub.com/doi/10.1177/0956797617747090},
  urldate = {2019-08-31},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\HRUN9XAA\\Kulke et al. - 2018 - Is Implicit Theory of Mind a Real and Robust Pheno.pdf},
  keywords = {open developmental science,replication},
  langid = {english},
  number = {6},
  options = {useprefix=true}
}

@article{lamprechtFAIRPrinciplesResearch2019,
  title = {Towards {{FAIR}} Principles for Research Software},
  author = {Lamprecht, Anna-Lena and Garcia, Leyla and Kuzak, Mateusz and Martinez, Carlos and Arcila, Ricardo and Martin Del Pico, Eva and Dominguez Del Angel, Victoria and van de Sandt, Stephanie and Ison, Jon and Martinez, Paula Andrea and McQuilton, Peter and Valencia, Alfonso and Harrow, Jennifer and Psomopoulos, Fotis and Gelpi, Josep Ll. and Chue Hong, Neil and Goble, Carole and Capella-Gutierrez, Salvador},
  editor = {Groth, Paul},
  date = {2019-11-13},
  journaltitle = {Data Science},
  shortjournal = {DS},
  pages = {1--23},
  issn = {24518492, 24518484},
  doi = {10.3233/DS-190026},
  url = {https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/DS-190026},
  urldate = {2020-05-19},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\4YVQJARQ\\Lamprecht et al_2019_Towards FAIR principles for research software.pdf},
  options = {useprefix=true}
}

@report{leveltFailingScienceFraudulent2012,
  title = {Failing Science: {{The}} Fraudulent Research Practices of Social Psychologist {{Diederik Stapel}} ({{Falende}} Wetenschap: {{De}} Frauduleuze Onderzoekspraktijken van Sociaal-Psycholoog {{Diederik Stapel}})},
  author = {Levelt, J. M., Willem and Noort,, E. and Drenth, P. J. D.},
  date = {2012},
  url = {https://www.onderwijsbrabant.nl/sites/default/files/eindrapport_stapel_nov_2012.pdf},
  urldate = {2020-02-08},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\9R88L72R\\eindrapport_stapel_nov_2012.pdf}
}

@article{lindsayResearchPreregistration1012016,
  title = {Research {{Preregistration}} 101},
  author = {Lindsay, D. Stephen and Simons, Daniel J. and Lilienfeld, Scott O.},
  date = {2016-11-30},
  journaltitle = {APS Observer},
  volume = {29},
  url = {https://www.psychologicalscience.org/observer/research-preregistration-101},
  urldate = {2020-01-30},
  abstract = {Psychological Science Editor in Chief D. Stephen Lindsay, Clinical Psychological Science Editor Scott O. Lilienfeld, and APS Fellow Daniel J. Simons explain the rationale for and benefits of preregistration, for researchers and for the field of psychological science at large.},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\BVSBXU6L\\research-preregistration-101.html},
  langid = {american},
  number = {10}
}

@article{linRecommendationsRolePublishers2014,
  title = {Recommendations for the {{Role}} of {{Publishers}} in {{Access}} to {{Data}}},
  author = {Lin, Jennifer and Strasser, Carly},
  date = {2014-10-28},
  journaltitle = {PLoS Biology},
  shortjournal = {PLoS Biol},
  volume = {12},
  pages = {e1001975},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.1001975},
  url = {https://dx.plos.org/10.1371/journal.pbio.1001975},
  urldate = {2020-11-05},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\K5XYCBJB\\Lin_Strasser_2014_Recommendations for the Role of Publishers in Access to Data.pdf},
  langid = {english},
  number = {10}
}

@article{martinArePsychologyJournals2017,
  title = {Are {{Psychology Journals Anti}}-Replication? {{A Snapshot}} of {{Editorial Practices}}},
  shorttitle = {Are {{Psychology Journals Anti}}-Replication?},
  author = {Martin, G. N. and Clarke, Richard M.},
  date = {2017},
  journaltitle = {Frontiers in Psychology},
  shortjournal = {Front. Psychol.},
  volume = {8},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2017.00523},
  url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2017.00523/full},
  urldate = {2019-08-31},
  abstract = {Recent research in psychology has highlighted a number of replication problems in the discipline, with publication bias – the preference for publishing original and positive results, and a resistance to publishing negative results and replications- identified as one reason for replication failure. However, little empirical research exists to demonstrate that journals explicitly refuse to publish replications. We reviewed the instructions to authors and the published aims of 1151 psychology journals and examined whether they indicated that replications were permitted and accepted. We also examined whether journal practices differed across branches of the discipline, and whether editorial practices differed between low and high impact journals. Thirty three journals (3\%) stated in their aims or instructions to authors that they accepted replications. There was no difference between high and low impact journals. The implications of these findings for psychology are discussed.},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\IB4FH5YA\\Martin and Clarke - 2017 - Are Psychology Journals Anti-replication A Snapsh.pdf},
  keywords = {JOURNAL EDITORIAL PRACTICES,open developmental science,p-hacking,Psychology,Publication Bias,Replication},
  langid = {english}
}

@article{mclean2019empirical,
  title = {The Empirical Structure of Narrative Identity: {{The}} Initial {{Big Three}}.},
  author = {McLean, Kate C and Syed, Moin and Pasupathi, Monisha and Adler, Jonathan M and Dunlop, William L and Drustrup, David and Fivush, Robyn and Graci, Matthew E and Lilgendahl, Jennifer P and Lodi-Smith, Jennifer and others},
  date = {2019},
  journaltitle = {Journal of personality and social psychology},
  publisher = {{American Psychological Association}},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\XABPPFSJ\\McLean,etal,NarrativeStructure-inpressJPSP.pdf}
}

@article{moreauMetaanalysisTemplatesMaterials2019,
  title = {Meta-Analysis Templates and Materials},
  author = {Moreau, David and Gamble, Beau},
  date = {2019-11-28},
  doi = {None},
  url = {https://osf.io/q8stz/},
  urldate = {2020-01-08},
  abstract = {Hosted on the Open Science Framework},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\ZI3WLI64\\q8stz.html},
  langid = {english}
}

@online{muenchenPopularityDataScience2012,
  title = {The {{Popularity}} of {{Data Science Software}}},
  author = {Muenchen, Robert A.},
  date = {2012-04-25T23:22:32+00:00},
  journaltitle = {r4stats.com},
  url = {http://r4stats.com/articles/popularity/},
  urldate = {2020-01-08},
  abstract = {by Abstract This article, formerly known as The Popularity of Data Analysis Software, presents various ways of measuring the popularity or market share of software for advanced a…},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\WEGIDWCV\\popularity.html},
  langid = {american}
}

@book{national2009being,
  title = {On Being a Scientist: A Guide to Responsible Conduct in Research},
  author = {National Academy of Sciences},
  date = {2009},
  edition = {3},
  publisher = {{National Academies Press (US)}},
  location = {{Washington, DC, US}}
}

@article{nosekPromotingOpenResearch2015a,
  title = {Promoting an Open Research Culture},
  author = {Nosek, B. A. and Alter, G. and Banks, G. C. and Borsboom, D. and Bowman, S. D. and Breckler, S. J. and Buck, S. and Chambers, C. D. and Chin, G. and Christensen, G. and Contestabile, M. and Dafoe, A. and Eich, E. and Freese, J. and Glennerster, R. and Goroff, D. and Green, D. P. and Hesse, B. and Humphreys, M. and Ishiyama, J. and Karlan, D. and Kraut, A. and Lupia, A. and Mabry, P. and Madon, T. and Malhotra, N. and Mayo-Wilson, E. and McNutt, M. and Miguel, E. and Paluck, E. Levy and Simonsohn, U. and Soderberg, C. and Spellman, B. A. and Turitto, J. and VandenBos, G. and Vazire, S. and Wagenmakers, E. J. and Wilson, R. and Yarkoni, T.},
  date = {2015-06-26},
  journaltitle = {Science},
  volume = {348},
  pages = {1422--1425},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aab2374},
  url = {https://science.sciencemag.org/content/348/6242/1422},
  urldate = {2019-09-01},
  abstract = {Author guidelines for journals could help to promote transparency, openness, and reproducibility Author guidelines for journals could help to promote transparency, openness, and reproducibility},
  eprint = {26113702},
  eprinttype = {pmid},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\7JEB688L\\Nosek et al_2015_Promoting an open research culture.pdf;C\:\\Users\\lissa102\\Zotero\\storage\\ZKLD8GV8\\1422.html},
  langid = {english},
  number = {6242}
}

@article{nosekScientificUtopiaOpening2012,
  title = {Scientific {{Utopia}}: {{I}}. {{Opening Scientific Communication}}},
  shorttitle = {Scientific {{Utopia}}},
  author = {Nosek, Brian A. and Bar-Anan, Yoav},
  date = {2012-07-01},
  journaltitle = {Psychological Inquiry},
  volume = {23},
  pages = {217--243},
  issn = {1047-840X},
  doi = {10.1080/1047840X.2012.692215},
  url = {https://doi.org/10.1080/1047840X.2012.692215},
  urldate = {2020-02-05},
  abstract = {Existing norms for scientific communication are rooted in anachronistic practices of bygone eras making them needlessly inefficient. We outline a path that moves away from the existing model of scientific communication to improve the efficiency in meeting the purpose of public science—knowledge accumulation. We call for six changes: (a) full embrace of digital communication; (b) open access to all published research; (c) disentangling publication from evaluation; (d) breaking the “one article, one journal” model with a grading system for evaluation and diversified dissemination outlets; (e) publishing peer review; and (f) allowing open, continuous peer review. We address conceptual and practical barriers to change and provide examples showing how the suggested practices are being used already. The critical barriers to change are not technical or financial; they are social. Although scientists guard the status quo, they also have the power to change it.},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\PK3KU64G\\Nosek_Bar-Anan_2012_Scientific Utopia.pdf;C\:\\Users\\lissa102\\Zotero\\storage\\JTSJWCMS\\1047840X.2012.html},
  number = {3}
}

@article{nowokSynthpopBespokeCreation2016,
  title = {Synthpop: {{Bespoke Creation}} of {{Synthetic Data}} in {{R}}},
  shorttitle = {Synthpop},
  author = {Nowok, Beata and Raab, Gillian M. and Dibben, Chris},
  date = {2016-10-28},
  journaltitle = {Journal of Statistical Software},
  volume = {74},
  pages = {1--26},
  issn = {1548-7660},
  doi = {10.18637/jss.v074.i11},
  url = {https://www.jstatsoft.org/index.php/jss/article/view/v074i11},
  urldate = {2020-05-18},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\GVM22GB5\\Nowok et al_2016_synthpop.pdf;C\:\\Users\\lissa102\\Zotero\\storage\\S9GYFN2L\\v074i11.html},
  issue = {1},
  keywords = {CART,disclosure control,R,synthetic data,UK longitudinal studies},
  langid = {english},
  number = {1}
}

@software{oomsGertSimpleGit2019,
  title = {Gert: {{Simple}} Git Client for r},
  author = {Ooms, Jeroen},
  date = {2019},
  url = {https://CRAN.R-project.org/package=gert}
}

@article{patilVisualToolDefining2019,
  title = {A Visual Tool for Defining Reproducibility and Replicability},
  author = {Patil, Prasad and Peng, Roger D. and Leek, Jeffrey T.},
  date = {2019-07},
  journaltitle = {Nature Human Behaviour},
  volume = {3},
  pages = {650--652},
  publisher = {{Nature Publishing Group}},
  issn = {2397-3374},
  doi = {10.1038/s41562-019-0629-z},
  url = {https://www.nature.com/articles/s41562-019-0629-z},
  urldate = {2020-11-01},
  abstract = {Reproducibility and replicability are fundamental requirements of scientific studies. Disagreements over universal definitions for these terms have affected the interpretation of large-scale replication attempts. We provide a visual tool for representing definitions and use it to re-examine these attempts.},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\EDRP7RMR\\Patil et al_2019_A visual tool for defining reproducibility and replicability.pdf;C\:\\Users\\lissa102\\Zotero\\storage\\FTA3GGQ8\\s41562-019-0629-z.html},
  issue = {7},
  langid = {english},
  number = {7}
}

@article{peikertReproducibleDataAnalysis2019,
  title = {A {{Reproducible Data Analysis Workflow}} with {{R Markdown}}, {{Git}}, {{Make}}, and {{Docker}}},
  author = {Peikert, Aaron and Brandmaier, Andreas Markus},
  date = {2019-11-11T15:08:01.530Z},
  doi = {10.31234/osf.io/8xzqy},
  url = {https://psyarxiv.com/8xzqy/},
  urldate = {2020-01-09},
  abstract = {In this tutorial, we describe a workflow to ensure long-term reproducibility of R-based data analyses. The workflow leverages established tools and practices from software engineering. It combines the benefits of various open-source software tools including R Markdown, Git, Make, and Docker, whose interplay ensures seamless integration of version management, dynamic report generation conforming to various journal styles and full cross-platform and long-term computational reproducibility. The workflow ensures meeting the primary goals that 1) the reporting of statistical results is consistent with the actual statistical results (dynamic report generation), the analysis exactly reproduces at a later time even if the computing platform or software is changed (computational reproducibility), and 3) changes at any time (during development and post-publication) are tracked, tagged, and documented while earlier versions of both data and code remain accessible.  While the research community increasingly recognizes dynamic document generation and version management as tools to ensure reproducibility, we demonstrate with practical examples that these alone are not sufficient to ensure long-term computational reproducibility. Leveraging containerization, dependence management, version management, and literate programming, the workflow increases scientific productivity by facilitating later reproducibility and reuse of code and data.},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\AS9JL74K\\Peikert_Brandmaier_2019_A Reproducible Data Analysis Workflow with R Markdown, Git, Make, and Docker.pdf;C\:\\Users\\lissa102\\Zotero\\storage\\2NT8MMMG\\8xzqy.html}
}

@online{pengSimpleExplanationReplication2016,
  title = {A {{Simple Explanation}} for the {{Replication Crisis}} in {{Science}} · {{Simply Statistics}}},
  author = {Peng, Roger},
  date = {2016-08-24},
  journaltitle = {Simplystats},
  url = {https://simplystatistics.org/2016/08/24/replication-crisis/},
  urldate = {2019-09-01},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\CMKAL9TN\\replication-crisis.html}
}

@article{phillipsDiscombobulationDeidentification2016,
  title = {The Discombobulation of De-Identification},
  author = {Phillips, Mark and Knoppers, Bartha M.},
  date = {2016-11},
  journaltitle = {Nature Biotechnology},
  volume = {34},
  pages = {1102--1103},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1696},
  doi = {10.1038/nbt.3696},
  url = {https://www.nature.com/articles/nbt.3696},
  urldate = {2020-05-25},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\PSFU6U7F\\Phillips_Knoppers_2016_The discombobulation of de-identification.pdf;C\:\\Users\\lissa102\\Zotero\\storage\\R8KX8PE5\\nbt.html},
  issue = {11},
  langid = {english},
  number = {11}
}

@article{plesserReproducibilityVsReplicability2018,
  title = {Reproducibility vs. {{Replicability}}: {{A Brief History}} of a {{Confused Terminology}}},
  shorttitle = {Reproducibility vs. {{Replicability}}},
  author = {Plesser, Hans E.},
  date = {2018},
  journaltitle = {Frontiers in Neuroinformatics},
  shortjournal = {Front. Neuroinform.},
  volume = {11},
  issn = {1662-5196},
  doi = {10.3389/fninf.2017.00076},
  url = {https://www.frontiersin.org/articles/10.3389/fninf.2017.00076/full},
  urldate = {2019-09-01},
  abstract = {Reproducibility vs. Replicability: A Brief History of a Confused Terminology},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\VSY3D595\\Plesser_2018_Reproducibility vs.pdf},
  keywords = {artifacts,computational science,repeatability,replicability,reproducibility},
  langid = {english}
}

@article{ramGitCanFacilitate2013,
  title = {Git Can Facilitate Greater Reproducibility and Increased Transparency in Science},
  author = {Ram, Karthik},
  date = {2013-02-28},
  journaltitle = {Source Code for Biology and Medicine},
  shortjournal = {Source Code for Biology and Medicine},
  volume = {8},
  pages = {7},
  issn = {1751-0473},
  doi = {10.1186/1751-0473-8-7},
  url = {https://doi.org/10.1186/1751-0473-8-7},
  urldate = {2020-01-08},
  abstract = {Reproducibility is the hallmark of good science. Maintaining a high degree of transparency in scientific reporting is essential not just for gaining trust and credibility within the scientific community but also for facilitating the development of new ideas. Sharing data and computer code associated with publications is becoming increasingly common, motivated partly in response to data deposition requirements from journals and mandates from funders. Despite this increase in transparency, it is still difficult to reproduce or build upon the findings of most scientific publications without access to a more complete workflow.},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\RZB63RDE\\Ram_2013_Git can facilitate greater reproducibility and increased transparency in science.pdf;C\:\\Users\\lissa102\\Zotero\\storage\\H4UH8INM\\1751-0473-8-7.html},
  number = {1}
}

@software{rcoreteamLanguageEnvironmentStatistical2020,
  title = {R: {{A Language}} and {{Environment}} for {{Statistical Computing}}},
  author = {{R Core Team}},
  date = {2020},
  location = {{Vienna, Austria}},
  url = {https://www.R-project.org/},
  organization = {{R Foundation for Statistical Computing}}
}

@book{repro,
  title = {Repro: {{Automated}} Setup of Reproducible Workflows and Their Dependencies},
  author = {Peikert, Aaron and Brandmaier, Andreas Markus and Van Lissa, Caspar J.},
  date = {2020},
  url = {https://github.com/aaronpeikert/repro}
}

@online{ReproducibleWorkflowVersion,
  title = {Reproducible Workflow and Version Control with {{Git}} and {{Github}}},
  url = {https://jules32.github.io/2016-07-12-Oxford/git/},
  urldate = {2019-10-26},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\7J672FN6\\git.html}
}

@report{rivest1992md5,
  title = {The {{MD5}} Message-Digest Algorithm},
  author = {Rivest, Ron},
  date = {1992-04},
  institution = {{MIT Laboratory for Computer Science and RSA Data Security, Inc.}}
}

@article{rooyenEffectPeerReview2010,
  title = {Effect on Peer Review of Telling Reviewers That Their Signed Reviews Might Be Posted on the Web: Randomised Controlled Trial},
  shorttitle = {Effect on Peer Review of Telling Reviewers That Their Signed Reviews Might Be Posted on the Web},
  author = {van Rooyen, Susan and Delamothe, Tony and Evans, Stephen J. W.},
  date = {2010-11-16},
  journaltitle = {BMJ},
  shortjournal = {BMJ},
  volume = {341},
  pages = {c5729},
  issn = {0959-8138, 1468-5833},
  doi = {10.1136/bmj.c5729},
  url = {https://www.bmj.com/content/341/bmj.c5729},
  urldate = {2019-10-25},
  abstract = {Objectives To see whether telling peer reviewers that their signed reviews of original research papers might be posted on the BMJ’s website would affect the quality of their reviews. Design Randomised controlled trial. Setting A large international general medical journal based in the United Kingdom. Participants 541 authors, 471 peer reviewers, and 12 editors. Intervention Consecutive eligible papers were randomised either to have the reviewer’s signed report made available on the BMJ’s website alongside the published paper (intervention group) or to have the report made available only to the author—the BMJ’s normal procedure (control group). The intervention was the act of revealing to reviewers—after they had agreed to review but before they undertook their review—that their signed report might appear on the website. Main outcome measures The main outcome measure was the quality of the reviews, as independently rated on a scale of 1 to 5 using a validated instrument by two editors and the corresponding author. Authors and editors were blind to the intervention group. Authors rated review quality before the fate of their paper had been decided. Additional outcomes were the time taken to complete the review and the reviewer’s recommendation regarding publication. Results 558 manuscripts were randomised, and 471 manuscripts remained after exclusions. Of the 1039 reviewers approached to take part in the study, 568 (55\%) declined. Two editors’ evaluations of the quality of the peer review were obtained for all 471 manuscripts, with the corresponding author’s evaluation obtained for 453. There was no significant difference in review quality between the intervention and control groups (mean difference for editors 0.04, 95\% CI −0.09 to 0.17; for authors 0.06, 95\% CI −0.09 to 0.20). Any possible difference in favour of the control group was well below the level regarded as editorially significant. Reviewers in the intervention group took significantly longer to review (mean difference 25 minutes, 95\% CI 3.0 to 47.0 minutes). Conclusion Telling peer reviewers that their signed reviews might be available in the public domain on the BMJ’s website had no important effect on review quality. Although the possibility of posting reviews online was associated with a high refusal rate among potential peer reviewers and an increase in the amount of time taken to write a review, we believe that the ethical arguments in favour of open peer review more than outweigh these disadvantages.},
  eprint = {21081600},
  eprinttype = {pmid},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\4LP5VZPE\\Rooyen et al_2010_Effect on peer review of telling reviewers that their signed reviews might be.pdf},
  langid = {english}
}

@article{rosenbergTidyLPAPackageEasily2018,
  title = {{{tidyLPA}}: {{An R Package}} to {{Easily Carry Out Latent Profile Analysis}} ({{LPA}}) {{Using Open}}-{{Source}} or {{Commercial Software}}},
  shorttitle = {{{tidyLPA}}},
  author = {Rosenberg, Joshua and Beymer, Patrick and Anderson, Daniel and Van Lissa, Caspar J. and Schmidt, Jennifer},
  date = {2018-10-10},
  journaltitle = {Journal of Open Source Software},
  volume = {3},
  pages = {978},
  issn = {2475-9066},
  doi = {10.21105/joss.00978},
  url = {https://joss.theoj.org/papers/10.21105/joss.00978},
  urldate = {2020-02-05},
  abstract = {Researchers are often interested in identifying homogeneous subgroups within heterogeneous samples on the basis of a set of measures, such as profiles of individuals’ motivation (i.e., their values, competence beliefs, and achievement goals). Latent Profile Analysis (LPA) is a statistical method for identifying such groups, or latent profiles, and is a special case of the general mixture model where all measured variables are continuous (Harring \& Hodis, 2016; Pastor, Barron, Miller, \& Davis, 2007). The tidyLPA package allows users to specify different models that determine whether and how different parameters (i.e., means, variances, and covariances) are estimated, and to specify and compare different solutions based on the number of profiles extracted.},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\JVGDVPE9\\Rosenberg et al. - 2018 - tidyLPA An R Package to Easily Carry Out Latent P.pdf},
  langid = {english},
  number = {30}
}

@article{ross-hellauerWhatOpenPeer2017,
  title = {What Is Open Peer Review? {{A}} Systematic Review},
  shorttitle = {What Is Open Peer Review?},
  author = {Ross-Hellauer, Tony},
  date = {2017-08-31},
  journaltitle = {F1000Research},
  shortjournal = {F1000Res},
  volume = {6},
  issn = {2046-1402},
  doi = {10.12688/f1000research.11369.2},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5437951/},
  urldate = {2019-10-25},
  abstract = {Background: “Open peer review” (OPR), despite being a major pillar of Open Science, has neither a standardized definition nor an agreed schema of its features and implementations. The literature reflects this, with numerous overlapping and contradictory definitions. While for some the term refers to peer review where the identities of both author and reviewer are disclosed to each other, for others it signifies systems where reviewer reports are published alongside articles. For others it signifies both of these conditions, and for yet others it describes systems where not only “invited experts” are able to comment. For still others, it includes a variety of combinations of these and other novel methods.,  Methods: Recognising the absence of a consensus view on what open peer review is, this article undertakes a systematic review of definitions of “open peer review” or “open review”, to create a corpus of 122 definitions. These definitions are systematically analysed to build a coherent typology of the various innovations in peer review signified by the term, and hence provide the precise technical definition currently lacking.,  Results: This quantifiable data yields rich information on the range and extent of differing definitions over time and by broad subject area. Quantifying definitions in this way allows us to accurately portray exactly how ambiguously the phrase “open peer review” has been used thus far, for the literature offers 22 distinct configurations of seven traits, effectively meaning that there are 22 different definitions of OPR in the literature reviewed.,  Conclusions: I propose a pragmatic definition of open peer review as an umbrella term for a number of overlapping ways that peer review models can be adapted in line with the aims of Open Science, including making reviewer and author identities open, publishing review reports and enabling greater participation in the peer review process.},
  eprint = {28580134},
  eprinttype = {pmid},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\IRD7VFHQ\\Ross-Hellauer_2017_What is open peer review.pdf},
  pmcid = {PMC5437951}
}

@software{rossRedocReversibleReproducible2020,
  title = {Redoc - {{Reversible Reproducible Documents}}},
  author = {Ross, Noam},
  date = {2020-01-30T09:19:37Z},
  origdate = {2018-12-01T21:10:44Z},
  url = {https://github.com/noamross/redoc},
  urldate = {2020-02-05},
  abstract = {Reversible Reproducible Documents. Contribute to noamross/redoc development by creating an account on GitHub.},
  version = {0.1.0.9000}
}

@online{RStudioPBC,
  title = {{{RStudio}}, {{PBC}}},
  url = {https://blog.rstudio.com/2020/01/29/rstudio-pbc/},
  urldate = {2020-10-31},
  abstract = {We started the RStudio project because we were excited and inspired by R. The creators of R provided a flexible and powerful foundation for statistical computing; then made it free and open so that it could be improved collaboratively and its benefits could be shared by the widest possible audience. It’s better for everyone if the tools used for research and science are free and open. Reproducibility, widespread sharing of knowledge and techniques, and the leveling of the playing field by eliminating cost barriers are but a few of the shared benefits of free software in science.},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\FVNASP9E\\rstudio-pbc.html},
  langid = {american}
}

@online{rstudioRStudioCertifiedCorporation2019,
  title = {{{RStudio}} | {{Certified B Corporation}}},
  author = {RStudio},
  date = {2019-12},
  url = {https://bcorporation.net/directory/rstudio},
  urldate = {2020-10-31},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\C4DJEQJS\\rstudio.html}
}

@book{rstudioteamRStudioIntegratedDevelopment2015,
  title = {{{RStudio}}: {{Integrated}} Development Environment for {{R}}},
  author = {{RStudio Team}},
  date = {2015},
  location = {{Boston, MA}},
  url = {http://www.rstudio.com/},
  organization = {{RStudio, Inc.}}
}

@article{shroutPsychologyScienceKnowledge2018,
  title = {Psychology, {{Science}}, and {{Knowledge Construction}}: {{Broadening Perspectives}} from the {{Replication Crisis}}},
  shorttitle = {Psychology, {{Science}}, and {{Knowledge Construction}}},
  author = {Shrout, Patrick E. and Rodgers, Joseph L.},
  date = {2018},
  journaltitle = {Annual Review of Psychology},
  volume = {69},
  pages = {487--510},
  doi = {10.1146/annurev-psych-122216-011845},
  url = {https://doi.org/10.1146/annurev-psych-122216-011845},
  urldate = {2019-08-31},
  abstract = {Psychology advances knowledge by testing statistical hypotheses using empirical observations and data. The expectation is that most statistically significant findings can be replicated in new data and in new laboratories, but in practice many findings have replicated less often than expected, leading to claims of a replication crisis. We review recent methodological literature on questionable research practices, meta-analysis, and power analysis to explain the apparently high rates of failure to replicate. Psychologists can improve research practices to advance knowledge in ways that improve replicability. We recommend that researchers adopt open science conventions of preregi-stration and full disclosure and that replication efforts be based on multiple studies rather than on a single replication attempt. We call for more sophisticated power analyses, careful consideration of the various influences on effect sizes, and more complete disclosure of nonsignificant as well as statistically significant findings.},
  eprint = {29300688},
  eprinttype = {pmid},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\VSW7FA4W\\Shrout and Rodgers - 2018 - Psychology, Science, and Knowledge Construction B.pdf},
  number = {1}
}

@article{sondervanCOVID19PandemicStresses2020,
  title = {The COVID-19 pandemic stresses the societal importance of open science},
  author = {Sondervan, Jeroen and Bosman, Jeroen and Kramer, Bianca and Brinkman, Loek and Imming, Melanie and Versteeg, Anke},
  date = {2020-04-03T10:27:20+00:00},
  journaltitle = {ScienceGuide},
  url = {https://www.scienceguide.nl/2020/04/dire-times-of-covid-19-stress-the-societal-importance-of-open-science/},
  urldate = {2020-09-25},
  abstract = {The COVID crisis fuels a rapid acceleration in open science, but still a lot of crucial sources are paywalled.},
  entrysubtype = {magazine},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\VZPKHV36\\dire-times-of-covid-19-stress-the-societal-importance-of-open-science.html},
  langid = {dutch}
}

@book{sonjabezjakOpenScienceTraining2018,
  title = {Open {{Science Training Handbook}}},
  author = {Sonja Bezjak and April Clyburne-Sherin and Philipp Conzett and Pedro Fernandes and Edit Görögh and Kerstin Helbig and Bianca Kramer and Ignasi Labastida and Kyle Niemeyer and Fotis Psomopoulos and Tony Ross-Hellauer and René Schneider and Jon Tennant and Ellen Verbakel and Helene Brinken and Lambert Heller},
  date = {2018-04-04},
  publisher = {{Zenodo}},
  doi = {10.5281/zenodo.1212496},
  url = {https://zenodo.org/record/1212496#.X7OKRWhKiUk},
  urldate = {2020-11-17},
  abstract = {For a readable version of the book, please visit https://book.fosteropenscience.eu A group of fourteen authors came together in February 2018 at the TIB (German National Library of Science and Technology) in Hannover to create an open, living handbook on Open Science training. High-quality trainings are fundamental when aiming at a cultural change towards the implementation of Open Science principles. Teaching resources provide great support for Open Science instructors and trainers. The Open Science training handbook will be a key resource and a first step towards developing Open Access and Open Science curricula and andragogies. Supporting and connecting an emerging Open Science community that wishes to pass on their knowledge as multipliers, the handbook will enrich training activities and unlock the community’s full potential. In this first release of the Open Science Training Handbook, some initial feedback from the community is already included.},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\GDXMGYEB\\1212496.html},
  keywords = {Open Science,Training,Translational skills,Vocational training},
  version = {1.0}
}

@article{stanleyReproducibleTablesPsychology2018,
  title = {Reproducible {{Tables}} in {{Psychology Using}} the {{apaTables Package}}},
  author = {Stanley, David J. and Spence, Jeffrey R.},
  date = {2018-09-01},
  journaltitle = {Advances in Methods and Practices in Psychological Science},
  shortjournal = {Advances in Methods and Practices in Psychological Science},
  volume = {1},
  pages = {415--431},
  issn = {2515-2459},
  doi = {10.1177/2515245918773743},
  url = {https://doi.org/10.1177/2515245918773743},
  urldate = {2020-01-03},
  abstract = {Growing awareness of how susceptible research is to errors, coupled with well-documented replication failures, has caused psychological researchers to move toward open science and reproducible research. In this Tutorial, to facilitate reproducible psychological research, we present a tool that creates reproducible tables that follow the American Psychological Association’s (APA’s) style. Our tool, apaTables, automates the creation of APA-style tables for commonly used statistics and analyses in psychological research: correlations, multiple regressions (with and without blocks), standardized mean differences, N-way independent-groups analyses of variance (ANOVAs), within-subjects ANOVAs, and mixed-design ANOVAs. All tables are saved as Microsoft Word documents, so they can be readily incorporated into manuscripts without manual formatting or transcription of values.},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\SYWRI2PD\\Stanley_Spence_2018_Reproducible Tables in Psychology Using the apaTables Package.pdf},
  keywords = {data sharing,open data,open materials,open science,R,replication,reproducibility,reproducible analyses,reproducible research,reproducible tables,statistical tools,transparency in research},
  langid = {english},
  number = {3}
}

@article{stoddenEnhancingReproducibilityComputational2016,
  title = {Enhancing Reproducibility for Computational Methods},
  author = {Stodden, Victoria and McNutt, Marcia and Bailey, David H. and Deelman, Ewa and Gil, Yolanda and Hanson, Brooks and Heroux, Michael A. and Ioannidis, John P. A. and Taufer, Michela},
  date = {2016-12-09},
  journaltitle = {Science},
  volume = {354},
  pages = {1240--1241},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aah6168},
  url = {https://science.sciencemag.org/content/354/6317/1240},
  urldate = {2020-11-17},
  abstract = {Over the past two decades, computational methods have radically changed the ability of researchers from all areas of scholarship to process and analyze data and to simulate complex systems. But with these advances come challenges that are contributing to broader concerns over irreproducibility in the scholarly literature, among them the lack of transparency in disclosure of computational methods. Current reporting methods are often uneven, incomplete, and still evolving. We present a novel set of Reproducibility Enhancement Principles (REP) targeting disclosure challenges involving computation. These recommendations, which build upon more general proposals from the Transparency and Openness Promotion (TOP) guidelines (1) and recommendations for field data (2), emerged from workshop discussions among funding agencies, publishers and journal editors, industry participants, and researchers representing a broad range of domains. Although some of these actions may be aspirational, we believe it is important to recognize and move toward ameliorating irreproducibility in computational research. Data, code, and workflows should be available and cited Data, code, and workflows should be available and cited},
  eprint = {27940837},
  eprinttype = {pmid},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\UCLA4G7Y\\Stodden et al_2016_Enhancing reproducibility for computational methods.pdf;C\:\\Users\\lissa102\\Zotero\\storage\\HRNJKYVZ\\1240.html},
  langid = {english},
  number = {6317}
}

@online{SupplementalUsingGit,
  title = {Supplemental: {{Using Git}} from {{RStudio}} – {{Version Control}} with {{Git}}},
  url = {https://swcarpentry.github.io/git-novice/14-supplemental-rstudio/index.html},
  urldate = {2019-10-26},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\7XNF7PKP\\index.html}
}

@unpublished{syedPromiseOpenScience2019,
  title = {The {{Promise}} of the {{Open Science Movement}} for {{Research}} on {{Identity}}},
  author = {Syed, Moin},
  date = {2019-05-14},
  url = {https://osf.io/7yb3s},
  urldate = {2019-08-31},
  abstract = {The open science movement has been gaining steam in numerous scientific disciplines (e.g., ecology, cancer biology, economics) as well as sub-disciplines of psychology (e.g., social, personality). These issues, however, have been scantly discussed in the context of identity research. This presentation will include an overview of core issues in the open science movement and how they apply to research on identity. Emphasis will be placed on how incorporating open science principles can improve both theoretical and empirical work on identity.},
  eventtitle = {International {{Society}} for {{Research}} on {{Identity}}},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\GTZZZWLT\\Syed - The Promise of the Open Science Movement for Resea.pdf},
  langid = {english},
  type = {Presidential address},
  venue = {{Naples, Italy}}
}

@online{TechBlogGitReproducibility,
  title = {{{TechBlog}}: {{Git}}: {{The}} Reproducibility Tool Scientists Love to Hate : {{Naturejobs Blog}}},
  url = {http://blogs.nature.com/naturejobs/2018/06/11/git-the-reproducibility-tool-scientists-love-to-hate/},
  urldate = {2019-10-26},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\UA5Y7BXZ\\git-the-reproducibility-tool-scientists-love-to-hate.html}
}

@unpublished{tennantOpenScienceJust2018,
  title = {Open Science Is Just Good Science},
  author = {Tennant, Jonathan},
  date = {2018},
  url = {https://figshare.com/articles/Open_Science_is_just_good_science_pptx/5783004},
  venue = {{TU Delft}}
}

@article{tennantValuePropositionOpen2020,
  title = {A Value Proposition for {{Open Science}}},
  author = {Tennant, Jonathan},
  date = {2020-03-09},
  journaltitle = {SocArxiv},
  doi = {10.31235/osf.io/k9qhv},
  url = {https://osf.io/k9qhv},
  urldate = {2020-05-23},
  abstract = {Open Science has become commonly understood in terms of its practices. Open Access, Open Data, and Open Source software are all becoming commonplace in academia. However, unlike the Free and Open Source Software movement, Open Science seems to have become largely divorced from its pluralistic philosophical and ethical foundations, which seem to have reignited from the humanities at the turn of the Millennium. To close this gap, I propose a new value-based proposition for Open Science, that is akin to the “four fundamental freedoms” of Richard Stallman that catalysed the Free Software movement. In doing so, I hope to provide a more common, unified, and human understanding to notions of openness in science.},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\EB4V8JX6\\Tennant - 2020 - A value proposition for Open Science.pdf},
  langid = {english}
}

@software{usheyRenvProjectEnvironments2020,
  title = {Renv: {{Project}} Environments},
  author = {Ushey, Kevin},
  date = {2020},
  url = {https://CRAN.R-project.org/package=renv},
  version = {0.12.0}
}

@article{vanlissaWORCSWorkflowOpen2020,
  title = {{{WORCS}}: {{A Workflow}} for {{Open Reproducible Code}} in {{Science}}},
  shorttitle = {{{WORCS}}},
  author = {Van Lissa, Caspar J. and Brandmaier, Andreas M. and Brinkman, Loek and Lamprecht, Anna-Lena and Peikert, Aaron and Struiksma, Marijn E. and Vreede, Barbara},
  date = {2020-05-29},
  publisher = {{OSF}},
  doi = {10.17605/OSF.IO/ZCVBS},
  url = {https://osf.io/zcvbs/},
  urldate = {2020-05-06},
  abstract = {Hosted on the Open Science Framework},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\4A72PMFS\\zcvbs.html},
  langid = {english}
}

@article{vantveerPreregistrationSocialPsychology2016,
  title = {Pre-Registration in Social Psychology—{{A}} Discussion and Suggested Template},
  author = {van 't Veer, Anna Elisabeth and Giner-Sorolla, Roger},
  date = {2016-11},
  journaltitle = {Journal of Experimental Social Psychology},
  shortjournal = {Journal of Experimental Social Psychology},
  volume = {67},
  pages = {2--12},
  issn = {00221031},
  doi = {10.1016/j.jesp.2016.03.004},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0022103116301925},
  urldate = {2020-01-30},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\4CHWSIJB\\van 't Veer_Giner-Sorolla_2016_Pre-registration in social psychology—A discussion and suggested template.pdf},
  langid = {english},
  options = {useprefix=true}
}

@article{vicente-saezOpenScienceNow2018,
  title = {Open {{Science}} Now: {{A}} Systematic Literature Review for an Integrated Definition},
  shorttitle = {Open {{Science}} Now},
  author = {Vicente-Saez, Ruben and Martinez-Fuentes, Clara},
  date = {2018-07-01},
  journaltitle = {Journal of Business Research},
  shortjournal = {Journal of Business Research},
  volume = {88},
  pages = {428--436},
  issn = {0148-2963},
  doi = {10.1016/j.jbusres.2017.12.043},
  url = {http://www.sciencedirect.com/science/article/pii/S0148296317305441},
  urldate = {2020-11-01},
  abstract = {Open Science is a disruptive phenomenon that is emerging around the world and especially in Europe. Open Science brings about socio-cultural and technological change, based on openness and connectivity, on how research is designed, performed, captured, and assessed. Several studies show that there is a lack of awareness about what Open Science is, mainly due to the fact that there is no formal definition of Open Science. The purpose of this paper is to build a rigorous, integrated, and up-to-date definition of the Open Science phenomenon through a systematic literature review. The resulting definition “Open Science is transparent and accessible knowledge that is shared and developed through collaborative networks” helps the scientific community, the business world, political actors, and citizens to have a common and clear understanding about what Open Science is, and stimulates an open debate about the social, economic, and human added value of this phenomenon.},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\8Q7UDT89\\S0148296317305441.html},
  keywords = {Definition,Open access,Open innovation,Open science,Research and innovation management,Responsible research and innovation},
  langid = {english}
}

@article{walshOpenPeerReview2000,
  title = {Open Peer Review: {{A}} Randomised Controlled Trial},
  shorttitle = {Open Peer Review},
  author = {Walsh, Elizabeth and Rooney, Maeve and Appleby, Louis and Wilkinson, Greg},
  date = {2000-01},
  journaltitle = {The British Journal of Psychiatry},
  volume = {176},
  pages = {47--51},
  issn = {0007-1250, 1472-1465},
  doi = {10.1192/bjp.176.1.47},
  url = {https://www.cambridge.org/core/journals/the-british-journal-of-psychiatry/article/open-peer-review-a-randomised-controlled-trial/1F81447FC67B3BAFDCCCCE82B6C7A187},
  urldate = {2019-10-25},
  abstract = {Background Most scientific journals practise anonymous peer review. There is no evidence, however, that this is any better than an open system. Aims To evaluate the feasibility of an open peer review system. Method Reviewers for the British Journal of Psychiatry were asked whether they would agree to have their name revealed to the authors whose papers they review; 408 manuscripts assigned to reviewers who agreed were randomised to signed or unsigned groups. We measured review quality, tone, recommendation for publication and time taken to complete each review. Results A total of 245 reviewers (76\%) agreed to sign. Signed reviews were of higher quality, were more courteous and took longer to complete than unsigned reviews. Reviewers who signed were more likely to recommend publication. Conclusions This study supports the feasibility of an open peer review system and identifies such a system's potential drawbacks.},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\LT9ETGKG\\Walsh et al_2000_Open peer review.pdf;C\:\\Users\\lissa102\\Zotero\\storage\\YZMR76SL\\1F81447FC67B3BAFDCCCCE82B6C7A187.html},
  langid = {english},
  number = {1}
}

@article{westonRecommendationsIncreasingTransparency2019,
  title = {Recommendations for {{Increasing}} the {{Transparency}} of {{Analysis}} of {{Preexisting Data Sets}}},
  shorttitle = {Recommendations for {{Increasing}} the {{Transparency}} of {{Analysis}} of {{Preexisting Data Sets}}},
  author = {Weston, Sara J. and Ritchie, Stuart J. and Rohrer, Julia M. and Przybylski, Andrew K.},
  date = {2019-06-11},
  journaltitle = {Advances in Methods and Practices in Psychological Science},
  doi = {10.1177/2515245919848684},
  url = {https://journals.sagepub.com/doi/10.1177/2515245919848684},
  urldate = {2020-01-23},
  abstract = {Secondary data analysis, or the analysis of preexisting data, provides a powerful tool for the resourceful psychological scientist. Never has this been more tru...},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\DE7WSWWM\\Weston et al_2019_Recommendations for Increasing the Transparency of Analysis of Preexisting Data.pdf;C\:\\Users\\lissa102\\Zotero\\storage\\IX2RRN5Z\\2515245919848684.html},
  langid = {english}
}

@article{wickhamTidyData2014,
  title = {Tidy {{Data}}},
  author = {Wickham, Hadley},
  date = {2014-09-12},
  journaltitle = {Journal of Statistical Software},
  volume = {59},
  pages = {1--23},
  issn = {1548-7660},
  doi = {10.18637/jss.v059.i10},
  url = {https://www.jstatsoft.org/index.php/jss/article/view/v059i10},
  urldate = {2020-05-18},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\XJ5UTIN7\\Wickham_2014_Tidy Data.pdf;C\:\\Users\\lissa102\\Zotero\\storage\\VR53BUBH\\v059i10.html},
  issue = {1},
  langid = {english},
  number = {1}
}

@article{wilkinsonFAIRGuidingPrinciples2016a,
  title = {The {{FAIR Guiding Principles}} for Scientific Data Management and Stewardship},
  author = {Wilkinson, Mark D. and Dumontier, Michel and Aalbersberg, IJsbrand Jan and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and da Silva Santos, Luiz Bonino and Bourne, Philip E. and Bouwman, Jildau and Brookes, Anthony J. and Clark, Tim and Crosas, Mercè and Dillo, Ingrid and Dumon, Olivier and Edmunds, Scott and Evelo, Chris T. and Finkers, Richard and Gonzalez-Beltran, Alejandra and Gray, Alasdair J.G. and Groth, Paul and Goble, Carole and Grethe, Jeffrey S. and Heringa, Jaap and ’t Hoen, Peter A.C and Hooft, Rob and Kuhn, Tobias and Kok, Ruben and Kok, Joost and Lusher, Scott J. and Martone, Maryann E. and Mons, Albert and Packer, Abel L. and Persson, Bengt and Rocca-Serra, Philippe and Roos, Marco and van Schaik, Rene and Sansone, Susanna-Assunta and Schultes, Erik and Sengstag, Thierry and Slater, Ted and Strawn, George and Swertz, Morris A. and Thompson, Mark and van der Lei, Johan and van Mulligen, Erik and Velterop, Jan and Waagmeester, Andra and Wittenburg, Peter and Wolstencroft, Katherine and Zhao, Jun and Mons, Barend},
  date = {2016-12},
  journaltitle = {Scientific Data},
  shortjournal = {Sci Data},
  volume = {3},
  pages = {160018},
  issn = {2052-4463},
  doi = {10.1038/sdata.2016.18},
  url = {http://www.nature.com/articles/sdata201618},
  urldate = {2020-05-19},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\EYCPVCGR\\Wilkinson et al_2016_The FAIR Guiding Principles for scientific data management and stewardship.pdf},
  langid = {english},
  number = {1},
  options = {useprefix=true}
}

@software{worcspackage2020,
  title = {Worcs: {{Workflow}} for Open Reproducible Code in Science},
  author = {Van Lissa, Caspar J. and Peikert, Aaron and Brandmaier, Andreas M.},
  date = {2020-05-29},
  url = {https://cran.r-project.org/web/packages/worcs/index.html},
  version = {0.1.5}
}

@online{wrightRangerFastImplementation2015,
  title = {Ranger: {{A Fast Implementation}} of {{Random Forests}} for {{High Dimensional Data}} in {{C}}++ and {{R}}},
  shorttitle = {Ranger},
  author = {Wright, Marvin N. and Ziegler, Andreas},
  date = {2015-08-18},
  url = {http://arxiv.org/abs/1508.04409},
  abstract = {We introduce the C++ application and R package ranger. The software is a fast implementation of random forests for high dimensional data. Ensembles of classification, regression and survival trees are supported. We describe the implementation, provide examples, validate the package with a reference implementation, and compare runtime and memory usage with other implementations. The new software proves to scale best with the number of features, samples, trees, and features tried for splitting. Finally, we show that ranger is the fastest and most memory efficient implementation of random forests to analyze data on the scale of a genome-wide association study.},
  archivePrefix = {arXiv},
  eprint = {1508.04409},
  eprinttype = {arxiv},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\2QCM8EU7\\Wright_Ziegler_2015_ranger.pdf;C\:\\Users\\lissa102\\Zotero\\storage\\W7MZ7V4J\\1508.html},
  keywords = {Statistics - Computation,Statistics - Machine Learning},
  primaryClass = {stat}
}

@book{xieMarkdownDefinitiveGuide2018,
  title = {R {{Markdown}}: {{The Definitive Guide}}},
  shorttitle = {R {{Markdown}}},
  author = {Xie, Yihui and Allaire, J. J. and Grolemund, Garrett},
  date = {2018},
  publisher = {{Chapman and Hall/CRC}},
  url = {https://bookdown.org/yihui/rmarkdown/},
  urldate = {2020-10-28},
  abstract = {The first official book authored by the core R Markdown developers that provides a comprehensive and accurate reference to the R Markdown ecosystem. With R Markdown, you can easily create reproducible data analysis reports, presentations, dashboards, interactive applications, books, dissertations, websites, and journal articles, while enjoying the simplicity of Markdown and the great power of R and other languages.},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\3BBCK525\\rmarkdown.html},
  isbn = {978-1-138-35933-8},
  series = {The {{R Series}}}
}

@article{yamadaHowCrackPreregistration2018,
  title = {How to {{Crack Pre}}-Registration: {{Toward Transparent}} and {{Open Science}}},
  shorttitle = {How to {{Crack Pre}}-Registration},
  author = {Yamada, Yuki},
  date = {2018-09-26},
  journaltitle = {Frontiers in Psychology},
  volume = {9},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2018.01831},
  url = {https://www.frontiersin.org/article/10.3389/fpsyg.2018.01831/full},
  urldate = {2020-02-16},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\TBFHD98N\\Yamada - 2018 - How to Crack Pre-registration Toward Transparent .pdf},
  langid = {english}
}

@online{ZombieLiterature,
  title = {The {{Zombie Literature}}},
  journaltitle = {The Scientist Magazine®},
  url = {https://www.the-scientist.com/features/the-zombie-literature-33627},
  urldate = {2019-10-25},
  abstract = {Retractions are on the rise. But reams of flawed research papers persist in the scientific literature. Is it time to change the way papers are published?},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\HQTCXNXY\\the-zombie-literature-33627.html},
  langid = {english}
}


